{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BdM3lBcbZ9Qw"
      },
      "outputs": [],
      "source": [
        "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from torch import tensor,nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastcore.test import test_close\n",
        "\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "torch.manual_seed(1)\n",
        "mpl.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "MNIST_URL = 'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
        "\n",
        "path_data = Path('data')\n",
        "path_data.mkdir(exist_ok=True)\n",
        "path_gz = path_data/'mnist.pkl.gz'\n",
        "from urllib.request import urlretrieve\n",
        "if not path_gz.exists():\n",
        "    urlretrieve(MNIST_URL , path_gz)\n",
        "\n",
        "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
      ],
      "metadata": {
        "id": "nkhtBWtCZ_7k"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh=50"
      ],
      "metadata": {
        "id": "l0Z-xwDXaGqE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6JKO2i1Ka-i6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Model(m, nh, 10)\n",
        "pred = model(x_train)\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1ncUPfrbD0O",
        "outputId": "aa0d9c41-2a4e-48cc-dbb6-c34dd079d302"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross Entropy"
      ],
      "metadata": {
        "id": "bhoevXaPbH8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first we need to compute softmax of our activation \n",
        "\n",
        "$softmax(x)$\n",
        "\n",
        "\\begin{equation}\n",
        "log-softmax(z_j) = log (\\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}})\n",
        "\\end{equation}\n",
        "<br>\n",
        "\\begin{equation}\n",
        "log-softmax(z_j) = x - log (\\sum_{k=1}^K e^{z_k})\n",
        "\\end{equation}\n"
      ],
      "metadata": {
        "id": "DJ-bjUs2cFxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  return (x.exp() / x.exp().sum(-1 , keepdim=True)).log()\n",
        "\n",
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1 , keepdim=True).log()\n"
      ],
      "metadata": {
        "id": "ALvtGGNqbKug"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "\n",
        "<br>\n",
        "\n",
        "$\n",
        "log (\\sum_{k=1}^K e^{z_k}) = log (e^a\\sum_{j=1}^n e^{z_j - a}) = a + log (\\sum_{j=1}^n e^{z_j - a}) \n",
        " $\n",
        "\n",
        " where is maximum among all, now exponential will not explode"
      ],
      "metadata": {
        "id": "osw7khkRm-Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  a = x.max(-1)[0]\n",
        "  return x - a - (x -a[:,None]).exp().sum(-1 , keepdim=True).log()\n",
        "\n",
        "def log_softmax(x): \n",
        "  return x - x.logsumexp(-1,keepdim=True)\n"
      ],
      "metadata": {
        "id": "vx4IA1Rlm9pv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = log_softmax(pred)"
      ],
      "metadata": {
        "id": "lsDUrLoD7OgL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross entropy  = $-\\sum x log p (x)$\n",
        "\n",
        "but since $x_i$ are one hot encoding , so we can write it as   $-log p(x_i)$ \n",
        "   where i is index of true class "
      ],
      "metadata": {
        "id": "qnSL5jbvo2V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nll(input , target):\n",
        "  return -input[range(target.shape[0]) , target].mean()"
      ],
      "metadata": {
        "id": "koHnV1eMbGUl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nll(sm , y_train)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okk1Op6P7ixY",
        "outputId": "a490f19c-6308-40c3-904a-d3e3c4fcae1e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.30, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(loss , F.nll_loss(F.log_softmax(pred,-1),y_train))"
      ],
      "metadata": {
        "id": "_-8wovxL71g8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_close(loss , F.cross_entropy(pred,y_train))"
      ],
      "metadata": {
        "id": "fgZq8g207s66"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "so basically = F.cross_entropy = F.nll_loss ( F.softmax(x) , target )  = $-log(p_i)$ where $p_i = x - log (\\sum_{k=1}^K e^{z_k})$"
      ],
      "metadata": {
        "id": "uZyhQ66A8Hqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = F.cross_entropy\n",
        "\n",
        "bs = 50\n",
        "xb = x_train[0:bs]\n",
        "pred = model(xb)\n",
        "pred.shape\n",
        "yb = y_train[:bs]"
      ],
      "metadata": {
        "id": "TYIzgVeW8oTI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "def accuracy(out , yb):\n",
        "  return (out.argmax(dim=1) == yb).float().mean()\n",
        "\n",
        "def report(loss , preds ,yb):\n",
        "  print(f\"loss : {loss:.2f}  accuracy : {accuracy(preds,yb):.2f}\")"
      ],
      "metadata": {
        "id": "I2aqIjx585rp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(pred , yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_7QAbKZ9JXJ",
        "outputId": "8d0b7d43-bf5c-4fcd-b6c2-069ba5d77758"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.08)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = .5\n",
        "epochs=3"
      ],
      "metadata": {
        "id": "d8hJ5GvS9bTU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0,n,bs):\n",
        "    s = slice(i , min(n,i+bs))\n",
        "    xb,yb = x_train[s] , y_train[s]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred,yb)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l ,'weight'):\n",
        "          l.weight -= lr * l.weight.grad\n",
        "          l.bias -= lr * l.bias.grad\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()\n",
        "  report(loss,pred,yb)      \n",
        "          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtNqKKOK9khg",
        "outputId": "7e80908f-1ba2-4e7b-feaf-99c404efd12c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 0.07  accuracy : 0.98\n",
            "loss : 0.06  accuracy : 0.98\n",
            "loss : 0.03  accuracy : 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###using parameters and optim"
      ],
      "metadata": {
        "id": "K6h4ALSf_XTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = nn.Module()\n",
        "m1.foo = nn.Linear(2,3)\n",
        "m1 , list(m1.named_children()) , list(m1.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_uAKqTt_WuS",
        "outputId": "7eb394dd-58dd-4bda-ec94-24ee50507eaf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Module(\n",
              "   (foo): Linear(in_features=2, out_features=3, bias=True)\n",
              " ),\n",
              " [('foo', Linear(in_features=2, out_features=3, bias=True))],\n",
              " [Parameter containing:\n",
              "  tensor([[ 0.07,  0.51],\n",
              "          [ 0.49, -0.21],\n",
              "          [-0.60, -0.20]], requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([ 0.44,  0.29, -0.15], requires_grad=True)])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
      ],
      "metadata": {
        "id": "l63ZGti5_0Z8"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =Model(m,nh,10)"
      ],
      "metadata": {
        "id": "yq-OLOKN_1tW"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range(0,n,bs):\n",
        "    s = slice(i , min(n,i+bs))\n",
        "    xb,yb = x_train[s] , y_train[s]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred,yb)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      for p in model.parameters():\n",
        "        p -= p.grad * lr\n",
        "        p.grad.zero_()\n",
        "  report(loss,pred,yb)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl6h296b__hS",
        "outputId": "425bbfc4-0be0-4e2d-8bf7-16fb42e734c4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 0.17  accuracy : 0.94\n",
            "loss : 0.17  accuracy : 0.96\n",
            "loss : 0.11  accuracy : 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]\n"
      ],
      "metadata": {
        "id": "qmTiC0SWAVu4"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x\n",
        "     "
      ],
      "metadata": {
        "id": "-KHpPRY0Asoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer():\n",
        "  def __init__(self,params , lr=.5):\n",
        "    self.param = list(params)\n",
        "    self.lr=lr\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.param:\n",
        "        p -= p.grad * self.lr\n",
        "  \n",
        "  def zero_grad(self):\n",
        "    for p in self.param:\n",
        "      p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "v2dvLLaXBEg_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n"
      ],
      "metadata": {
        "id": "YqmRNoU8Bva5"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "metadata": {
        "id": "Z9jWMlAuBz6u"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        s = slice(i, min(n,i+bs))\n",
        "        xb,yb = x_train[s],y_train[s]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ACUTJCB0rn",
        "outputId": "32842aff-5f81-4bb7-eff8-b93c72c5ea5c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 0.10  accuracy : 0.98\n",
            "loss : 0.06  accuracy : 0.98\n",
            "loss : 0.04  accuracy : 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "ng0HH5FZB2_e"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.SGD(model.parameters() , lr=lr)"
      ],
      "metadata": {
        "id": "-oN1R6heCtKk"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        s = slice(i, min(n,i+bs))\n",
        "        xb,yb = x_train[s],y_train[s]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbDGTFNwCw4t",
        "outputId": "8c255752-eac3-4e87-846b-73932e6d8150"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 0.03  accuracy : 1.00\n",
            "loss : 0.02  accuracy : 1.00\n",
            "loss : 0.02  accuracy : 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset and dataloader"
      ],
      "metadata": {
        "id": "XlI8iuW3DcZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "  def __init__(self,x,y):\n",
        "    self.x=x\n",
        "    self.y=y\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.x[idx] , self.y[idx]"
      ],
      "metadata": {
        "id": "v_SxbIdCC7kA"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n"
      ],
      "metadata": {
        "id": "2EMsQ8hBDRoS"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, n, bs):\n",
        "        xb,yb = train_ds[i:min(n,i+bs)]\n",
        "        preds = model(xb)\n",
        "        loss = loss_func(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    report(loss, preds, yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSH34b5LDU7K",
        "outputId": "ef373da8-c886-42ac-a0c5-33f4ba11f14e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 0.02  accuracy : 1.00\n",
            "loss : 0.02  accuracy : 1.00\n",
            "loss : 0.02  accuracy : 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "  def __init__(self,ds,bs):\n",
        "    self.ds,self.bs = ds,bs\n",
        "  def __iter__(self):\n",
        "      for i in range(0 , len(self.ds) , self.bs):\n",
        "        yield self.ds[i:i+self.bs]"
      ],
      "metadata": {
        "id": "6K3z1hIbDbQC"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)\n",
        "     "
      ],
      "metadata": {
        "id": "TWdBUb3NExEj"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            preds = model(xb)\n",
        "            loss = loss_func(preds, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        report(loss, preds, yb)"
      ],
      "metadata": {
        "id": "_7iHO4ZLEzox"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg__nYV7E28D",
        "outputId": "82e3588c-b82a-42a8-ca38-331e7f09fcd3"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 0.02  accuracy : 0.98\n",
            "loss : 0.04  accuracy : 0.98\n",
            "loss : 0.05  accuracy : 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "random sampling"
      ],
      "metadata": {
        "id": "l_ckLP1DFASi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class Sampler():\n",
        "  def __init__(self,ds,shuffle=True):\n",
        "    self.n = len(ds)\n",
        "    self.shuffle=shuffle\n",
        "  \n",
        "  def __iter__(self):\n",
        "    res = list(range(self.n))\n",
        "    if self.shuffle:\n",
        "      random.shuffle(res)\n",
        "    return iter(res)"
      ],
      "metadata": {
        "id": "wzelFKEMFH3r"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler =Sampler(train_ds)"
      ],
      "metadata": {
        "id": "DyiYI-aEFo5j"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(sampler)\n",
        "for i in range(5):\n",
        "  print(next(it))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frxkTNFWFrxw",
        "outputId": "41735507-b71c-4325-bc51-c81974ade930"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14384\n",
            "8243\n",
            "14175\n",
            "15839\n",
            "46259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fastcore.all as fc\n",
        "from itertools import islice\n",
        "\n",
        "class BatchSampler():\n",
        "  def __init__(self,sampler,bs,drop_last=False):\n",
        "    fc.store_attr()\n",
        "  def __iter__(self):\n",
        "    yield from fc.chunked(iter(self.sampler) , self.bs,drop_last = self.drop_last)"
      ],
      "metadata": {
        "id": "4S9xBo2mF_eU"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batchs = BatchSampler(sampler, 4)\n",
        "list(islice(batchs, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDTWBgk6GhIR",
        "outputId": "fbd2b7af-7e63-41e1-ed95-7ad75eb883bf"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4991, 7249, 42900, 36293],\n",
              " [13328, 45454, 15119, 4105],\n",
              " [18975, 35679, 14940, 44077],\n",
              " [25958, 28677, 9631, 28058],\n",
              " [12017, 42339, 28122, 112]]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate(b):\n",
        "  xs,ys = zip(*b)\n",
        "  return torch.stack(xs),torch.stack(ys)"
      ],
      "metadata": {
        "id": "txWKxlYsGrb2"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "  def __init__(self , ds,batchs,collate_fn = collate):\n",
        "    fc.store_attr()\n",
        "\n",
        "  def __iter__(self):\n",
        "    yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
      ],
      "metadata": {
        "id": "yjwxyTwmG2Zf"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_samp = BatchSampler(Sampler(train_ds, shuffle=True ), bs)\n",
        "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
      ],
      "metadata": {
        "id": "GbGXprkxHf-f"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
        "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
      ],
      "metadata": {
        "id": "yAmxEeUoHjI_"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler\n"
      ],
      "metadata": {
        "id": "p9DbhBXMHmDH"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samp = BatchSampler(RandomSampler(train_ds),     bs, drop_last=False)\n",
        "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
      ],
      "metadata": {
        "id": "2mlS9NmZH2Zx"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)\n"
      ],
      "metadata": {
        "id": "edgYsX8IH4su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "metadata": {
        "id": "AujYSEdFGxxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}